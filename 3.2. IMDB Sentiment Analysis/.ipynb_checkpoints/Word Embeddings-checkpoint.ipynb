{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings:\n",
    "Word2Vec and GloVe are the two popular models to create word embedding of a text. These models takes a text corpus as input and produces the word vectors as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Stanford GloVe model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors \n",
    "filename = r'C:\\Users\\Monish Kumar\\Python projects\\# Natural Language Proccessing\\GoogleNews-vectors-negative300.bin.gz'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08007812,  0.10498047,  0.04980469,  0.0534668 , -0.06738281,\n",
       "       -0.12060547,  0.03515625, -0.11865234,  0.04394531,  0.03015137,\n",
       "       -0.05688477, -0.07617188,  0.01287842,  0.04980469, -0.08496094,\n",
       "       -0.06347656,  0.00628662, -0.04321289,  0.02026367,  0.01330566,\n",
       "       -0.01953125,  0.09277344, -0.171875  , -0.00131989,  0.06542969,\n",
       "        0.05834961, -0.08251953,  0.0859375 , -0.00318909,  0.05859375,\n",
       "       -0.03491211, -0.0123291 , -0.0480957 , -0.00302124,  0.05639648,\n",
       "        0.01495361, -0.07226562, -0.05224609,  0.09667969,  0.04296875,\n",
       "       -0.03540039, -0.07324219,  0.03271484, -0.06176758,  0.00787354,\n",
       "        0.0035553 , -0.00878906,  0.0390625 ,  0.03833008,  0.04443359,\n",
       "        0.06982422,  0.01263428, -0.00445557, -0.03320312, -0.04272461,\n",
       "        0.09765625, -0.02160645, -0.0378418 ,  0.01190186, -0.01391602,\n",
       "       -0.11328125,  0.09326172, -0.03930664, -0.11621094,  0.02331543,\n",
       "       -0.01599121,  0.02636719,  0.10742188, -0.00466919,  0.09619141,\n",
       "        0.0279541 , -0.05395508,  0.08544922, -0.03686523, -0.02026367,\n",
       "       -0.08544922,  0.125     ,  0.14453125,  0.0267334 ,  0.15039062,\n",
       "        0.05273438, -0.18652344,  0.08154297, -0.01062012, -0.03735352,\n",
       "       -0.07324219, -0.07519531,  0.03613281, -0.13183594,  0.00616455,\n",
       "        0.05078125,  0.04516602,  0.0100708 , -0.15039062, -0.06005859,\n",
       "        0.05761719, -0.00692749,  0.01586914, -0.0213623 ,  0.10351562,\n",
       "       -0.00029182, -0.046875  , -0.01635742, -0.07861328, -0.06933594,\n",
       "        0.01635742, -0.03149414, -0.01373291, -0.03662109, -0.08886719,\n",
       "       -0.0480957 , -0.01318359, -0.07177734,  0.00588989, -0.04614258,\n",
       "        0.03979492,  0.10058594, -0.04931641,  0.07568359,  0.03881836,\n",
       "       -0.16699219, -0.09619141, -0.10107422,  0.02905273, -0.05786133,\n",
       "       -0.01928711, -0.04296875, -0.08398438, -0.01989746,  0.05151367,\n",
       "        0.00848389, -0.03613281, -0.14941406, -0.01855469, -0.03637695,\n",
       "       -0.07666016, -0.03955078, -0.06152344, -0.02001953,  0.04150391,\n",
       "        0.03686523, -0.07226562,  0.00592041, -0.06298828,  0.00738525,\n",
       "       -0.01586914,  0.01611328, -0.01452637,  0.00772095,  0.10107422,\n",
       "       -0.00558472,  0.01428223, -0.07617188,  0.05639648, -0.01293945,\n",
       "        0.03063965, -0.02490234, -0.09863281,  0.0324707 , -0.02807617,\n",
       "       -0.08105469,  0.02062988,  0.01611328, -0.04199219, -0.03491211,\n",
       "       -0.03759766,  0.05493164,  0.01373291,  0.02685547, -0.05859375,\n",
       "       -0.07177734, -0.12011719, -0.02282715, -0.1640625 , -0.00361633,\n",
       "       -0.05981445,  0.07080078, -0.07714844,  0.05175781, -0.04296875,\n",
       "       -0.04833984,  0.0300293 , -0.06591797, -0.03173828, -0.04882812,\n",
       "       -0.03491211,  0.05883789, -0.01464844,  0.18066406,  0.05688477,\n",
       "        0.05249023,  0.05786133,  0.11669922,  0.05200195, -0.0534668 ,\n",
       "        0.01867676, -0.015625  ,  0.00576782, -0.07324219, -0.11621094,\n",
       "        0.04052734,  0.0625    , -0.04321289,  0.01055908,  0.02172852,\n",
       "        0.04248047,  0.03271484,  0.04418945,  0.05761719,  0.02612305,\n",
       "       -0.01831055, -0.02697754, -0.00674438,  0.00509644, -0.11621094,\n",
       "        0.00364685,  0.05761719, -0.05957031, -0.08837891,  0.0135498 ,\n",
       "        0.04541016, -0.04638672, -0.0177002 , -0.0625    ,  0.03442383,\n",
       "       -0.02416992,  0.03088379,  0.09570312,  0.07958984,  0.03930664,\n",
       "        0.0279541 , -0.0859375 ,  0.08105469,  0.06640625, -0.00041962,\n",
       "       -0.06933594,  0.03588867, -0.03417969,  0.04492188, -0.00772095,\n",
       "       -0.00741577, -0.04760742,  0.01397705, -0.09960938,  0.0246582 ,\n",
       "       -0.09960938,  0.11474609,  0.03173828,  0.02209473,  0.07226562,\n",
       "        0.03686523,  0.02563477,  0.01367188, -0.02734375,  0.00592041,\n",
       "       -0.06738281,  0.05053711, -0.02832031, -0.04516602, -0.01733398,\n",
       "        0.02111816,  0.03515625, -0.04296875,  0.06640625,  0.12207031,\n",
       "        0.12353516,  0.0039978 ,  0.04516602, -0.01855469,  0.04833984,\n",
       "        0.04516602,  0.08691406,  0.02941895,  0.03759766,  0.03442383,\n",
       "       -0.07373047, -0.0402832 , -0.14648438, -0.02441406, -0.01953125,\n",
       "        0.0065918 , -0.0018158 , -0.01092529,  0.09326172,  0.06542969,\n",
       "        0.01843262, -0.09326172, -0.01574707, -0.07128906, -0.08935547,\n",
       "       -0.07128906, -0.03015137, -0.01300049,  0.01635742, -0.01831055,\n",
       "        0.01483154,  0.00500488,  0.00366211,  0.04760742, -0.06884766],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20409012\n",
      "0.3144896\n"
     ]
    }
   ],
   "source": [
    "# Finding the degree of similarity between two words.\n",
    "print(model.similarity('Doctor','man'))\n",
    "print(model.similarity('doctor','man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071)]\n",
      "[('homemaker', 0.5627118945121765)]\n",
      "[('gynecologist', 0.7093892097473145), ('nurse', 0.647728681564331)]\n"
     ]
    }
   ],
   "source": [
    "# Most similar analogies\n",
    "print(model.most_similar(positive=['woman','king'],negative=['man'],topn=1))\n",
    "print(model.most_similar(positive=['woman','computer_programmer'],negative=['man'],topn=1))\n",
    "print(model.most_similar(positive=['woman','doctor'],negative=['man'],topn=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd one out: cereal\n",
      "Singular/Plural: girls\n",
      "Gender - remaining examples of gender: female\n"
     ]
    }
   ],
   "source": [
    "# Finding odd one out.\n",
    "print('Odd one out:',model.doesnt_match('breakfast cereal dinner lunch'.split()))\n",
    "print('Singular/Plural:',model.doesnt_match('girls boy man woman'.split()))\n",
    "print('Gender - remaining examples of gender:',model.doesnt_match('girl boy man female'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model on your corpus:\n",
    "\n",
    "#### Attributes:\n",
    "- sentence – list of list of our corpus\n",
    "- min_count=1 – the threshold value for the words. Word with frequency greater than this only are going to be included into the model.\n",
    "- size=300 – the number of dimensions in which we wish to represent our word. This is the size of the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009307608\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Conda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Conda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [['data', 'science'], ['vidhya', 'science', 'data', 'analytics'],['machine', 'learning'], ['deep', 'learning']]\n",
    "\n",
    "# Training the model on your corpus  \n",
    "model1 = Word2Vec(sentences, min_count = 1, size = 300)\n",
    "\n",
    "print (model1.similarity('data', 'science'))\n",
    "print (len(model1['learning']))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
